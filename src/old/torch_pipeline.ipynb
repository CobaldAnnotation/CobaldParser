{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6426b364-1dfd-41cf-9264-7ed582748cb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# from common.sentence import Sentence\n",
    "# from common.parse_conllu import parse_conllu_incr\n",
    "\n",
    "# from lemmatize_helper import predict_lemma_rule\n",
    "# from utils import pad_matrices\n",
    "\n",
    "\n",
    "# class CobaldDataset(Dataset):\n",
    "#     # Alias for map from string to integer label.\n",
    "#     type Vocabulary = dict[str, int]\n",
    "\n",
    "#     def __init__(self, conllu_file_path: str, vocabularies: dict[str, Vocabulary] = None):\n",
    "#         fields = []\n",
    "#         with open(conllu_file_path, \"r\") as file:\n",
    "#             for sentence in parse_conllu_incr(file):\n",
    "#                 sentence_fields = self._process(sentence)\n",
    "#                 fields.append(sentence_fields)\n",
    "\n",
    "#         if vocabularies is None:\n",
    "#             vocabularies = self._build_vocabularies(fields)\n",
    "#         self._vocabularies = vocabularies\n",
    "\n",
    "#         self._fields_encoded = [self._encode_field(field, vocabularies) for field in fields]\n",
    "\n",
    "#     def vocabularies(self) -> dict[str, Vocabulary]:\n",
    "#         return self._vocabularies\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self._fields_encoded)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self._fields_encoded[index]\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _process(sentence: Sentence) -> dict[str, list[str]]:\n",
    "#         words = sentence.words\n",
    "#         lemmas = sentence.lemmas\n",
    "#         upos = sentence.upos\n",
    "#         xpos = sentence.xpos\n",
    "#         feats = sentence.feats\n",
    "#         heads = sentence.heads\n",
    "#         deprels = sentence.deprels\n",
    "#         deps = sentence.deps\n",
    "#         miscs = sentence.miscs\n",
    "#         deepslots = sentence.semslots\n",
    "#         semclasses = sentence.semclasses\n",
    "#         metadata = sentence.metadata\n",
    "\n",
    "#         lemma_rules: list[str] = None\n",
    "#         if lemmas is not None:\n",
    "#             lemma_rules = [\n",
    "#                 str(predict_lemma_rule(word if word is not None else '', lemma if lemma is not None else ''))\n",
    "#                 for word, lemma in zip(words, lemmas, strict=True)\n",
    "#             ]\n",
    "\n",
    "#         joint_pos_feats: list[str] = None\n",
    "#         if upos is not None and xpos is not None and feats is not None:\n",
    "#             joint_feats = [\n",
    "#                 '|'.join([f\"{k}={v}\" for k, v in feat.items()]) if 0 < len(feat) else '_'\n",
    "#                 for feat in feats\n",
    "#             ]\n",
    "#             joint_pos_feats = [\n",
    "#                 f\"{token_upos}#{token_xpos}#{token_joint_feats}\"\n",
    "#                 for token_upos, token_xpos, token_joint_feats in zip(upos, xpos, joint_feats, strict=True)\n",
    "#             ]\n",
    "\n",
    "#         sequence_length = len(words)\n",
    "\n",
    "#         deps_matrix_ud = None\n",
    "#         if heads is not None and deprels is not None:\n",
    "#             deps_matrix_ud = [[''] * sequence_length for _ in range(sequence_length)]\n",
    "#             for index, (head, relation) in enumerate(zip(heads, deprels, strict=True)):\n",
    "#                 # Skip nulls.\n",
    "#                 if head == -1:\n",
    "#                     continue\n",
    "#                 assert 0 <= head\n",
    "#                 # Hack: start indexing at 0 and replace ROOT with self-loop.\n",
    "#                 # It makes parser implementation much easier.\n",
    "#                 if head == 0:\n",
    "#                     # Replace ROOT with self-loop.\n",
    "#                     head = index\n",
    "#                 else:\n",
    "#                     # If not ROOT, shift token left.\n",
    "#                     head -= 1\n",
    "#                     assert head != index, f\"head = {head + 1} must not be equal to index = {index + 1}\"\n",
    "#                 deps_matrix_ud[index][head] = relation\n",
    "\n",
    "#         deps_matrix_eud = None\n",
    "#         if deps is not None:\n",
    "#             deps_matrix_eud = [[''] * sequence_length for _ in range(sequence_length)]\n",
    "#             for index, dep in enumerate(deps):\n",
    "#                 assert 0 < len(dep), f\"Deps must not be empty\"\n",
    "#                 for head, relation in dep.items():\n",
    "#                     assert 0 <= head\n",
    "#                     # Hack: start indexing at 0 and replace ROOT with self-loop.\n",
    "#                     # It makes parser implementation much easier.\n",
    "#                     if head == 0:\n",
    "#                         # Replace ROOT with self-loop.\n",
    "#                         head = index\n",
    "#                     else:\n",
    "#                         # If not ROOT, shift token left.\n",
    "#                         head -= 1\n",
    "#                         assert head != index, f\"head = {head + 1} must not be equal to index = {index + 1}\"\n",
    "#                     deps_matrix_eud[index][head] = relation\n",
    "\n",
    "#         return {\n",
    "#             \"words\": words,\n",
    "#             \"lemma_rules\": lemma_rules,\n",
    "#             \"joint_pos_feats\": joint_pos_feats,\n",
    "#             \"deps_ud\": deps_matrix_ud,\n",
    "#             \"deps_eud\": deps_matrix_eud,\n",
    "#             \"miscs\": miscs,\n",
    "#             \"deepslots\": deepslots,\n",
    "#             \"semclasses\": semclasses,\n",
    "#             \"metadata\": metadata\n",
    "#         }\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _build_vocabularies(fields: list[dict]) -> dict[str, Vocabulary]:\n",
    "        \n",
    "#         def enumerate_column(fields, column: str, is_matrix = False) -> list[str]:\n",
    "#             \"\"\"Extract unique labels from a specified column from fields.\"\"\"\n",
    "#             if is_matrix:\n",
    "#                 all_labels = [value for field in fields for matrix in field[column] for value in matrix]\n",
    "#             else:\n",
    "#                 all_labels = [value for field in fields for value in field[column]]\n",
    "#             # Ensure consistent ordering of labels\n",
    "#             unique_labels = sorted(set(all_labels))\n",
    "#             return {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "#         return {\n",
    "#             \"lemma_rules\": enumerate_column(fields, \"lemma_rules\"),\n",
    "#             \"joint_pos_feats\": enumerate_column(fields, \"joint_pos_feats\"),\n",
    "#             \"deps_ud\": enumerate_column(fields, \"deps_ud\", is_matrix=True),\n",
    "#             \"deps_eud\": enumerate_column(fields, \"deps_eud\", is_matrix=True),\n",
    "#             \"miscs\": enumerate_column(fields, \"miscs\"),\n",
    "#             \"deepslots\": enumerate_column(fields, \"deepslots\"),\n",
    "#             \"semclasses\": enumerate_column(fields, \"semclasses\")\n",
    "#         }\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _encode_field(field: dict[str, list], vocabularies: dict[str, Vocabulary]) -> dict:\n",
    "#         # print(field)\n",
    "#         encode_sequence_column = lambda column: torch.tensor(\n",
    "#             [vocabularies[column][val] for val in field[column]]\n",
    "#         )\n",
    "#         encode_matrix_column = lambda column: torch.tensor(\n",
    "#             [[vocabularies[column][val] for val in row] for row in field[column]]\n",
    "#         )\n",
    "#         return {\n",
    "#             \"lemma_rules\": encode_sequence_column(\"lemma_rules\"),\n",
    "#             \"joint_pos_feats\": encode_sequence_column(\"joint_pos_feats\"),\n",
    "#             \"deps_ud\": encode_matrix_column(\"deps_ud\"),\n",
    "#             \"deps_eud\": encode_matrix_column(\"deps_eud\"),\n",
    "#             \"miscs\": encode_sequence_column(\"miscs\"),\n",
    "#             \"deepslots\": encode_sequence_column(\"deepslots\"),\n",
    "#             \"semclasses\": encode_sequence_column(\"semclasses\")\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4425a5c2-f757-4597-b7ed-82de588755b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['The',\n",
       "  'firm',\n",
       "  \"'s\",\n",
       "  'snowmobile',\n",
       "  'division',\n",
       "  'and',\n",
       "  'defence',\n",
       "  'services',\n",
       "  'unit',\n",
       "  'were',\n",
       "  'also',\n",
       "  'sold',\n",
       "  'and',\n",
       "  'Bombardier',\n",
       "  'started',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'a',\n",
       "  'new',\n",
       "  'aircraft',\n",
       "  'seating',\n",
       "  '110',\n",
       "  'to',\n",
       "  '135',\n",
       "  'passengers',\n",
       "  '.'],\n",
       " 'lemma_rules': ['cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=1|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=1|cut_suffix=2|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=3|append_suffix=ell',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=2|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=3|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=1|append_suffix=',\n",
       "  'cut_prefix=0|cut_suffix=0|append_suffix='],\n",
       " 'joint_pos_feats': ['DET#Article#Definite=Def|PronType=Art',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'PART#_#_',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'CCONJ#Conjunction#_',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'NOUN#Noun#Number=Plur',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'AUX#Verb#Mood=Ind|Number=Plur|Person=3|Tense=Past|VerbForm=Fin',\n",
       "  'ADV#Adverb#_',\n",
       "  'VERB#Verb#Tense=Past|VerbForm=Part|Voice=Pass',\n",
       "  'CCONJ#Conjunction#_',\n",
       "  'PROPN#Noun#Number=Sing',\n",
       "  'VERB#Verb#Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "  'DET#Article#Definite=Def|PronType=Art',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'ADP#Preposition#_',\n",
       "  'DET#Article#Definite=Ind|PronType=Art',\n",
       "  'ADJ#Adjective#Degree=Pos',\n",
       "  'NOUN#Noun#Number=Sing',\n",
       "  'VERB#Verb#VerbForm=Ger',\n",
       "  'NUM#Numeral#NumForm=Digit|NumType=Card',\n",
       "  'ADP#Preposition#_',\n",
       "  'NUM#Numeral#NumForm=Digit|NumType=Card',\n",
       "  'NOUN#Noun#Number=Plur',\n",
       "  'PUNCT#PUNCT#_'],\n",
       " 'deps_ud': [['#',\n",
       "   'det',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nmod:poss',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   'case',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'compound',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nsubj:pass',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'cc',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'compound',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'compound',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'conj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'aux:pass',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'advmod',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'root',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'cc',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nsubj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'conj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'det',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'obj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'case',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'det',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'amod',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nmod',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'acl',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'obl',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'case',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nmod',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'obj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'punct',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#']],\n",
       " 'deps_eud': [['#',\n",
       "   'det',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nmod:poss',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   'case',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'compound',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nsubj:pass',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'cc',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'compound',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'compound',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'conj:and',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nsubj:pass',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'aux:pass',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'advmod',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'root',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'cc',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nsubj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'conj:and',\n",
       "   '#',\n",
       "   '#',\n",
       "   'root',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'det',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'obj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'case',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'det',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'amod',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nmod:of',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'acl',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'obl',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'case',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'nmod:to',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'obj',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#'],\n",
       "  ['#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   'punct',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#',\n",
       "   '#']],\n",
       " 'miscs': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'SpaceAfter=No',\n",
       "  '_'],\n",
       " 'deepslots': ['_',\n",
       "  'Whole',\n",
       "  '_',\n",
       "  'Object',\n",
       "  'Object',\n",
       "  '_',\n",
       "  'Object_Situation',\n",
       "  'Sphere',\n",
       "  'Object',\n",
       "  '_',\n",
       "  'Addition',\n",
       "  'Predicate',\n",
       "  '_',\n",
       "  'Agent',\n",
       "  'Predicate',\n",
       "  '_',\n",
       "  'Object_Situation',\n",
       "  '_',\n",
       "  '_',\n",
       "  'Time',\n",
       "  'Object',\n",
       "  'ParticipleRelativeClause',\n",
       "  'Quantity',\n",
       "  '_',\n",
       "  'Quantity',\n",
       "  'Object',\n",
       "  '_'],\n",
       " 'semclasses': ['ARTICLES',\n",
       "  'COMPANIES',\n",
       "  '_',\n",
       "  'TRANSPORT',\n",
       "  'PART_OF_ORGANIZATION',\n",
       "  'COORDINATING_CONJUNCTIONS',\n",
       "  'DEFEND_SAVE',\n",
       "  'TRANSPORT_COMMUNICATIONS',\n",
       "  'PART_OF_ORGANIZATION',\n",
       "  'AUXILIARY_VERBS',\n",
       "  'DISCOURSIVE_UNITS',\n",
       "  'TO_GIVE',\n",
       "  'COORDINATING_CONJUNCTIONS',\n",
       "  'COMPANIES',\n",
       "  'BEGIN_TO_TAKE_PLACE',\n",
       "  'ARTICLES',\n",
       "  'TO_MAKE',\n",
       "  'PREPOSITION',\n",
       "  'ARTICLES',\n",
       "  'CH_REFERENCE_AND_QUANTIFICATION',\n",
       "  'TRANSPORT',\n",
       "  'CONTAIN_INCLUDE_FORM',\n",
       "  'CH_REFERENCE_AND_QUANTIFICATION',\n",
       "  'PREPOSITION',\n",
       "  'CH_REFERENCE_AND_QUANTIFICATION',\n",
       "  'BEING',\n",
       "  '_'],\n",
       " 'metadata': {'sent_id': '2049',\n",
       "  'text': \"The firm's snowmobile division and defence services unit were also sold and Bombardier started the development of a new aircraft seating 110 to 135 passengers.\"}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import CobaldJointDataset\n",
    "\n",
    "train_dataset = CobaldJointDataset(\"../data/train.conllu\")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75464fbb-7cd9-426f-a4a5-142c191dcb41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACCESSORY': 0,\n",
       " 'ACT': 1,\n",
       " 'ACTIVITY': 2,\n",
       " 'ACTIVITY_BY_INTEREST': 3,\n",
       " 'ADMINISTRATIVE_REGION': 4,\n",
       " 'ADVENTURE': 5,\n",
       " 'AGGREGATE': 6,\n",
       " 'AGGREGATE_OF_LIVING_OBJECTS': 7,\n",
       " 'AGGREGATE_OF_MACHINERY_OR_TRANSPORT': 8,\n",
       " 'AGGRESSIVE_ACTIONS': 9,\n",
       " 'AGREEMENT_VERBS': 10,\n",
       " 'AGRICULTURAL_PROCESSING': 11,\n",
       " 'AMBIENCE_ENVIRONMENT': 12,\n",
       " 'ANIMAL': 13,\n",
       " 'APPARATUS': 14,\n",
       " 'AREA_OF_HUMAN_ACTIVITY': 15,\n",
       " 'ARRANGEMENTS': 16,\n",
       " 'ARTEFACT': 17,\n",
       " 'ARTICLES': 18,\n",
       " 'ATTRIBUTIVE': 19,\n",
       " 'AUXILIARY_VERBS': 20,\n",
       " 'BAD_DANGEROUS_EVENT': 21,\n",
       " 'BE': 22,\n",
       " 'BEGIN_TO_TAKE_PLACE': 23,\n",
       " 'BEHAVIOUR': 24,\n",
       " 'BEING': 25,\n",
       " 'BEVERAGE': 26,\n",
       " 'BE_STATE': 27,\n",
       " 'BIJOUTERIE_AND_JEWELLERY': 28,\n",
       " 'BODY': 29,\n",
       " 'BOOM': 30,\n",
       " 'BUSINESS': 31,\n",
       " 'BUSY_FREE_OCCUPIED': 32,\n",
       " 'CARGO': 33,\n",
       " 'CHANGE_OF_MATTER_PHYSICAL_STATE': 34,\n",
       " 'CHANGE_OF_ORGANIC_OBJECTS': 35,\n",
       " 'CHANGE_OF_POST_AND_JOB': 36,\n",
       " 'CHARACTERISTIC_GENERAL': 37,\n",
       " 'CHEMICAL_CHANGES': 38,\n",
       " 'CHOOSING_SORTING': 39,\n",
       " 'CH_ABSTRACT_GENERALIZED': 40,\n",
       " 'CH_APPEARANCE': 41,\n",
       " 'CH_ASPECT': 42,\n",
       " 'CH_BENEFIT': 43,\n",
       " 'CH_BY_RESIDENCE': 44,\n",
       " 'CH_BY_SENSORY_PERCEPTION': 45,\n",
       " 'CH_BY_WORLD_OUTLOOK_EDUCATION_AESTHETIC': 46,\n",
       " 'CH_CLASSIFICATION': 47,\n",
       " 'CH_COMPOSITION': 48,\n",
       " 'CH_CONFIGURATION_AND_FORM': 49,\n",
       " 'CH_COVERING': 50,\n",
       " 'CH_CRIMINAL_ACTIVITY': 51,\n",
       " 'CH_DEGREE': 52,\n",
       " 'CH_DEGREE_AND_INTENSITY': 53,\n",
       " 'CH_DISPOSITION_AND_MOTION': 54,\n",
       " 'CH_DISTRIBUTION': 55,\n",
       " 'CH_EVALUATION': 56,\n",
       " 'CH_EVALUATION_OF_HUMAN_TEMPER_AND_ACTIVITY': 57,\n",
       " 'CH_FULLNESS': 58,\n",
       " 'CH_FUNCTIONING_OF_ENTITY': 59,\n",
       " 'CH_INFORMATION': 60,\n",
       " 'CH_INTENTION_CONCENTRATION': 61,\n",
       " 'CH_LANGUAGE': 62,\n",
       " 'CH_MAGNITUDE': 63,\n",
       " 'CH_MEASURE': 64,\n",
       " 'CH_OF_BEING': 65,\n",
       " 'CH_OF_CONNECTIONS': 66,\n",
       " 'CH_OF_INTENSITY': 67,\n",
       " 'CH_OF_LOCATION': 68,\n",
       " 'CH_OF_VISUAL_AUDIBLE_REPRESENTATION': 69,\n",
       " 'CH_PARAMETER_OF_MATTER': 70,\n",
       " 'CH_PARAMETER_OF_OBJECT_AND_SUBSTANCE': 71,\n",
       " 'CH_PARAMETER_SPEED': 72,\n",
       " 'CH_PERCEPTIBILITY': 73,\n",
       " 'CH_PERSON_IDENTITY': 74,\n",
       " 'CH_PHYSICAL_STATE': 75,\n",
       " 'CH_POWER_AND_EFFECT': 76,\n",
       " 'CH_PRICE_AND_SUMS': 77,\n",
       " 'CH_REFERENCE_AND_QUANTIFICATION': 78,\n",
       " 'CH_RENOWN': 79,\n",
       " 'CH_RESISTANCE_TO_IMPACT': 80,\n",
       " 'CH_RHYTHM': 81,\n",
       " 'CH_SALIENCE': 82,\n",
       " 'CH_SCALE': 83,\n",
       " 'CH_SOCIAL_CHARACTERISTIC': 84,\n",
       " 'CH_SPHERE_OF_COVERAGE': 85,\n",
       " 'CH_STYLE': 86,\n",
       " 'CH_SURFACE_EDGE': 87,\n",
       " 'CH_SYSTEM_STRUCTURE': 88,\n",
       " 'CH_TYPE_OF_POSSESSION_AND_PARTICIPATION': 89,\n",
       " 'CIRCUMSTANCE': 90,\n",
       " 'CLASSIFICATION_TYPES': 91,\n",
       " 'CLASSIFICATION_UNIT': 92,\n",
       " 'CLOTHES': 93,\n",
       " 'COGNITIVE_OBJECT': 94,\n",
       " 'COMMUNICATIONS': 95,\n",
       " 'COMPANIES': 96,\n",
       " 'COMPOSITE_PARTICLES': 97,\n",
       " 'COMPOSITE_SUFFIXES': 98,\n",
       " 'CONDITIONS_IN_NATURE': 99,\n",
       " 'CONDITION_IN_ECONOMICS': 100,\n",
       " 'CONDITION_OF_EXPERIENCER_AND_NATURE': 101,\n",
       " 'CONDITION_SITUATION': 102,\n",
       " 'CONDITION_STATE': 103,\n",
       " 'CONFLICT_INTERACTION': 104,\n",
       " 'CONJUNCTIONS': 105,\n",
       " 'CONSTRUCTION_AS_WHOLE': 106,\n",
       " 'CONTACT_VERBS': 107,\n",
       " 'CONTACT_WITH_CONTRAGENT': 108,\n",
       " 'CONTAINER': 109,\n",
       " 'CONTAIN_INCLUDE_FORM': 110,\n",
       " 'CONTINUE_TO_HAVE': 111,\n",
       " 'CONTINUE_TO_TAKE_PLACE': 112,\n",
       " 'COORDINATING_CONJUNCTIONS': 113,\n",
       " 'CORRELATIVES': 114,\n",
       " 'COSMOS_AND_COSMIC_OBJECTS': 115,\n",
       " 'COST': 116,\n",
       " 'COUNTRY_AS_ADMINISTRATIVE_UNIT': 117,\n",
       " 'CREATION_VERBS': 118,\n",
       " 'CREATIVE_WORK': 119,\n",
       " 'CREATIVE_WORK_BY_GENRE': 120,\n",
       " 'CRISIS': 121,\n",
       " 'CULTURAL_RESEARCH_AND_EDUCATIONAL_INSTITUTIONS': 122,\n",
       " 'CULTURE': 123,\n",
       " 'DECLINE': 124,\n",
       " 'DECORATING_AND_FINISHING': 125,\n",
       " 'DEFEND_SAVE': 126,\n",
       " 'DEGREE_OF_FIT': 127,\n",
       " 'DEGREE_OF_SIZE_OR_SCALE': 128,\n",
       " 'DESTRUCTION_VERBS': 129,\n",
       " 'DEVICE': 130,\n",
       " 'DEVICE_FOR_ANIMALS': 131,\n",
       " 'DEVICE_FOR_CLOSING_AND_LOCKING': 132,\n",
       " 'DEVICE_FOR_HEATING': 133,\n",
       " 'DEVICE_FOR_LIFTING_OBJECTS': 134,\n",
       " 'DEVICE_FOR_MEASURING_AND_COUNTING': 135,\n",
       " 'DIFFICULTIES': 136,\n",
       " 'DIFFICULT_AND_EASY': 137,\n",
       " 'DIMENSION': 138,\n",
       " 'DIMENSIONS_CHAR': 139,\n",
       " 'DISCOURSIVE_UNITS': 140,\n",
       " 'DISTANT_CONTACT': 141,\n",
       " 'DOCUMENT': 142,\n",
       " 'DYNAMIC_ARTS': 143,\n",
       " 'ECONOMIC_CHANGES': 144,\n",
       " 'ECONOMY': 145,\n",
       " 'EFFICIENCY_PRODUCTIVITY': 146,\n",
       " 'ELECTIONS': 147,\n",
       " 'EMBARGO': 148,\n",
       " 'EMOTIONS_AND_THEIR_EXPRESSION': 149,\n",
       " 'EMPTY_SUBJECT': 150,\n",
       " 'ENDINGS': 151,\n",
       " 'ENGINEERING_COMMUNICATIONS': 152,\n",
       " 'ENTITY_AS_RESULT_OF_ACTIVITY': 153,\n",
       " 'ENTITY_BY_FUNCTION_AND_PROPERTY': 154,\n",
       " 'ENTITY_BY_RELATION_TO_MAIN_PART': 155,\n",
       " 'ENTITY_BY_VALUE': 156,\n",
       " 'ENTITY_GENERAL': 157,\n",
       " 'ENTITY_OR_SITUATION_PRONOUN': 158,\n",
       " 'ETIQUETTE_COMMUNICATION': 159,\n",
       " 'EVENT': 160,\n",
       " 'EVERYDAY_PROCESSING': 161,\n",
       " 'EXISTENCE_AND_POSSESSION': 162,\n",
       " 'FACT_INCIDENT': 163,\n",
       " 'FATE': 164,\n",
       " 'FEELING_AS_CONDITION': 165,\n",
       " 'FINE_ARTS_OBJECTS': 166,\n",
       " 'FOOD': 167,\n",
       " 'FORCE_IN_PHYSICS': 168,\n",
       " 'FREQUENCY_CHAR': 169,\n",
       " 'FURNISHINGS_AND_DECORATION': 170,\n",
       " 'GENERAL_ACTION': 171,\n",
       " 'GOOD_BAD_CONDITION': 172,\n",
       " 'GRAMMATICAL_ELEMENTS': 173,\n",
       " 'GROUP': 174,\n",
       " 'HAVE_CLOTHING_ON': 175,\n",
       " 'HERITAGE': 176,\n",
       " 'HIERARCHICAL_VERBS': 177,\n",
       " 'HISTORICAL_LOCALITY_BY_NAME': 178,\n",
       " 'HUMAN': 179,\n",
       " 'IDENTIFYING_ATTRIBUTE': 180,\n",
       " 'IDIOMATICAL_ELEMENTS': 181,\n",
       " 'INFORMATION': 182,\n",
       " 'INFORMATION_BEARER': 183,\n",
       " 'INFORMATION_COMMUNICATIONS': 184,\n",
       " 'INHABITED_LOCALITY': 185,\n",
       " 'INNOVATION': 186,\n",
       " 'INSTRUMENT': 187,\n",
       " 'INTELLECTUAL_ACTIVITY': 188,\n",
       " 'INTERPERSONAL_RELATIONS': 189,\n",
       " 'KIND': 190,\n",
       " 'KITCHENWARE_AND_TABLEWARE': 191,\n",
       " 'KNOWLEDGE': 192,\n",
       " 'KNOWLEDGE_FROM_EXPERIENCE': 193,\n",
       " 'KNOWLEDGE_FROM_EXPERIENCE_AND_DEDUCTION': 194,\n",
       " 'LACK_AND_PLENTY': 195,\n",
       " 'LAWS_AND_STANDARDS': 196,\n",
       " 'LINES': 197,\n",
       " 'LINE_FOR_COMMUNICATION': 198,\n",
       " 'LINGUISTIC_OBJECTS': 199,\n",
       " 'MAKE_EFFORTS': 200,\n",
       " 'MANAGE_FAIL_CONDITION': 201,\n",
       " 'MARKET_AS_AREA_OF_ACTIVITY': 202,\n",
       " 'MASS_MEDIA_ORGANIZATION_AND_COMMUNICATIONS': 203,\n",
       " 'MATERIALITY_CHAR': 204,\n",
       " 'MATHEMATICAL_OBJECTS': 205,\n",
       " 'MEANING_SENSE': 206,\n",
       " 'MEDICAL_OPERATIONS': 207,\n",
       " 'MENTAL_OBJECT': 208,\n",
       " 'METHOD_APPROACH_TECHNIQUE': 209,\n",
       " 'MILITARY_FORCES_AS_ORGANIZATION': 210,\n",
       " 'MIX_AS_AGGREGATE': 211,\n",
       " 'MODALITY': 212,\n",
       " 'MODE_OF_EXPRESSIVENESS': 213,\n",
       " 'MONEY': 214,\n",
       " 'MOTION': 215,\n",
       " 'MOTION_ACTIVITY': 216,\n",
       " 'MOTIVATE': 217,\n",
       " 'MOVEMENT_AS_ACTIVITY': 218,\n",
       " 'MULTIMEDIA': 219,\n",
       " 'MUSICAL_INSTRUMENT': 220,\n",
       " 'MYSTERY_SECRET': 221,\n",
       " 'NATURALNESS_GENUINENESS_CHAR': 222,\n",
       " 'NETWORK': 223,\n",
       " 'NONPRODUCTIVE_AREA': 224,\n",
       " 'NORMATIVE_LEGAL_ACTIVITY': 225,\n",
       " 'OBJECTS_BY_FORM_OF_MANIFESTATION': 226,\n",
       " 'OBJECTS_BY_FUNCTION': 227,\n",
       " 'OBJECT_BY_FUNCTION_AND_PROPERTY': 228,\n",
       " 'OBJECT_BY_SHAPE': 229,\n",
       " 'OBJECT_IN_NATURE': 230,\n",
       " 'OCCUPATIONS': 231,\n",
       " 'OPERATING_STATE': 232,\n",
       " 'OPTICAL_DEVICE_AND_ITS_PARTS': 233,\n",
       " 'ORDER_DISORDER': 234,\n",
       " 'ORGANIC_NON_ORGANIC': 235,\n",
       " 'ORGANIC_OBJECTS': 236,\n",
       " 'ORGANIZATION': 237,\n",
       " 'ORGANIZED_AGGREGATE': 238,\n",
       " 'ORIENTATION_IN_SPACE': 239,\n",
       " 'OUTFIT': 240,\n",
       " 'PARTICLES': 241,\n",
       " 'PARTS_OF_BODY': 242,\n",
       " 'PART_OF_ARTEFACT': 243,\n",
       " 'PART_OF_CLOTHES': 244,\n",
       " 'PART_OF_CONSTRUCTION': 245,\n",
       " 'PART_OF_CREATIVE_WORK': 246,\n",
       " 'PART_OF_FOOTWEAR': 247,\n",
       " 'PART_OF_ORGANISM': 248,\n",
       " 'PART_OF_ORGANIZATION': 249,\n",
       " 'PART_OF_WORLD': 250,\n",
       " 'PART_OR_PORTION_OF_ENTITY': 251,\n",
       " 'PATH_AS_DIRECTION_OF_ACTIVITY': 252,\n",
       " 'PEACE': 253,\n",
       " 'PERCEPTION_ACTIVITY': 254,\n",
       " 'PHENOMENON': 255,\n",
       " 'PHRASAL_PARTICLES': 256,\n",
       " 'PHYSICAL_AND_BIOLOGICAL_PROPERTIES': 257,\n",
       " 'PHYSICAL_CHEMICAL_DAMAGE': 258,\n",
       " 'PHYSICAL_OBJECT': 259,\n",
       " 'PHYSICAL_OBJECT_AND_SUBSTANCE_CHAR': 260,\n",
       " 'PHYSICAL_PSYCHIC_CONDITION': 261,\n",
       " 'PHYSIOLOGICAL_PROCESSES': 262,\n",
       " 'PLACE': 263,\n",
       " 'PLANT': 264,\n",
       " 'POINTS_AS_PLACE': 265,\n",
       " 'POSITION_AS_STATUS': 266,\n",
       " 'POSITION_IN_HIERARCHY': 267,\n",
       " 'POSITION_IN_SPACE': 268,\n",
       " 'POWER_CHAR': 269,\n",
       " 'POWER_RIGHT': 270,\n",
       " 'PREMISES': 271,\n",
       " 'PREPOSITION': 272,\n",
       " 'PRESSURE_CHAR': 273,\n",
       " 'PROBLEMS_TO_SOLVE': 274,\n",
       " 'PROCESSING': 275,\n",
       " 'PROCESS_AND_ITS_STAGES': 276,\n",
       " 'PROCESS_PARAMETER': 277,\n",
       " 'PRODUCT': 278,\n",
       " 'PRODUCTION_AS_TIME_ART': 279,\n",
       " 'PRODUCTIVE_AREA': 280,\n",
       " 'PUBLIC_ACTIVITY': 281,\n",
       " 'PUBLIC_AND_POLITICAL_ACTIVITY': 282,\n",
       " 'PUBLIC_SERVICE_INSTITUTIONS': 283,\n",
       " 'QUIETNESS': 284,\n",
       " 'READINESS': 285,\n",
       " 'REALITY': 286,\n",
       " 'RELATIVE_ENTITY': 287,\n",
       " 'RELATIVE_PART_OF_INHABITED_LOCALITY': 288,\n",
       " 'RELATIVE_SPACE': 289,\n",
       " 'RELIGIOUS_AND_MYTHOLOGICAL_CREATURE': 290,\n",
       " 'REMOVING_DESTRUCTION': 291,\n",
       " 'RESERVE': 292,\n",
       " 'RESULTS_OF_GIVING_INFORMATION_AND_SPEECH_ACTIVITY': 293,\n",
       " 'RESULTS_OF_MAKING_DECISIONS': 294,\n",
       " 'RESULTS_OF_MENTAL_ACTIVITY': 295,\n",
       " 'RESULT_CONSEQUENCE': 296,\n",
       " 'REVEAL_CONCEAL_INFORMATION': 297,\n",
       " 'REWARD_AS_ENTITY': 298,\n",
       " 'RISK_DANGER': 299,\n",
       " 'SAMPLE_AS_AGGREGATE': 300,\n",
       " 'SCALE_DIVISION': 301,\n",
       " 'SCHEDULE_FOR_ACTIVITY': 302,\n",
       " 'SCIENCE': 303,\n",
       " 'SCIENTIFIC_AND_LITERARY_WORK': 304,\n",
       " 'SEPARATION_PROCESSING': 305,\n",
       " 'SERIES_IN_SCIENCE': 306,\n",
       " 'SEXUAL_ACTIVITIES': 307,\n",
       " 'SILENCE_AS_SOUNDLESSNESS': 308,\n",
       " 'SITUATION': 309,\n",
       " 'SOCIAL_CONDITIONS_OF_BEING': 310,\n",
       " 'SOCIAL_INSTITUTIONS': 311,\n",
       " 'SPACE_AND_SPATIAL_OBJECTS': 312,\n",
       " 'SPACE_BY_PARTICULAR_PROPERTIES': 313,\n",
       " 'SPACE_BY_RELIGIOUS_BELIEFS': 314,\n",
       " 'SPACE_TIME_ART': 315,\n",
       " 'SPHERE_OF_ACTIVITY_GENERAL': 316,\n",
       " 'SPORT': 317,\n",
       " 'SPORT_DEVICE': 318,\n",
       " 'STAGNATION': 319,\n",
       " 'STATE_AREA': 320,\n",
       " 'STATE_AUTHORITIES': 321,\n",
       " 'STATE_OF_MIND': 322,\n",
       " 'STEADINESS_OF_FORM_OR_POSITION': 323,\n",
       " 'STREET_OR_TOWN_SUFFIXES': 324,\n",
       " 'SUBSTANCE': 325,\n",
       " 'SURFACE_AND_ITS_SPECIALITIES': 326,\n",
       " 'SYMBOLS_FOR_INFORMATION_TRANSFER': 327,\n",
       " 'SYSTEM_AS_AGGREGATE': 328,\n",
       " 'TEETH_AND_TONGUE_CONTACT': 329,\n",
       " 'TEMPERATURE_CHAR': 330,\n",
       " 'TENDENCY_AND_DISPOSITION': 331,\n",
       " 'TERRITORY_AREA': 332,\n",
       " 'TEST_FOR_EXPERIENCER': 333,\n",
       " 'TEXTS_OF_PROGRAMS': 334,\n",
       " 'TEXT_OBJECTS_AND_DOCUMENTS': 335,\n",
       " 'TEXT_WITH_ADDRESSEE': 336,\n",
       " 'THE_EARTH_AND_ITS_SPATIAL_PARTS': 337,\n",
       " 'THE_GOOD_BAD': 338,\n",
       " 'THE_MAGIC': 339,\n",
       " 'TIME': 340,\n",
       " 'TOPIC_SUBJECT': 341,\n",
       " 'TOTALITY_OF_DEGREE': 342,\n",
       " 'TO_ACCOMPANY_WITH': 343,\n",
       " 'TO_ACCUSE_AND_VINDICATE': 344,\n",
       " 'TO_ADAPT': 345,\n",
       " 'TO_ADD': 346,\n",
       " 'TO_ADJUST_AND_REPAIR': 347,\n",
       " 'TO_AIM': 348,\n",
       " 'TO_ANALYSE_AND_RESEARCH': 349,\n",
       " 'TO_ANIMATE_PICTURE': 350,\n",
       " 'TO_APPLAUD': 351,\n",
       " 'TO_APPLY_COAT': 352,\n",
       " 'TO_APPROACH_COME_TO_SOME_POINT_OR_STATE': 353,\n",
       " 'TO_ARREST': 354,\n",
       " 'TO_ASSEMBLE': 355,\n",
       " 'TO_ATTRIBUTE_AS_TO_ADD': 356,\n",
       " 'TO_AVOID': 357,\n",
       " 'TO_BEAT_AND_PRICK': 358,\n",
       " 'TO_BETRAY_AND_LEAVE': 359,\n",
       " 'TO_BE_ABOUT_TO_HAPPEN': 360,\n",
       " 'TO_BE_A_SIGN_OF': 361,\n",
       " 'TO_BE_BASED': 362,\n",
       " 'TO_BE_DESCENDED': 363,\n",
       " 'TO_BE_GUIDED': 364,\n",
       " 'TO_BE_SEEN_IN_FIELD_OF_VIEW': 365,\n",
       " 'TO_BLOW_UP': 366,\n",
       " 'TO_BREAK': 367,\n",
       " 'TO_BUILD': 368,\n",
       " 'TO_CALL_AND_DESIGNATE': 369,\n",
       " 'TO_CANCEL': 370,\n",
       " 'TO_CARE_AND_BRING_UP': 371,\n",
       " 'TO_CAUSE_OR_STOP_MOVEMENT': 372,\n",
       " 'TO_CAUSE_SUCCESS': 373,\n",
       " 'TO_CELEBRATE': 374,\n",
       " 'TO_CERTIFY': 375,\n",
       " 'TO_CHALLENGE_TO_INVITE': 376,\n",
       " 'TO_CHANGE': 377,\n",
       " 'TO_CHANGE_FORM': 378,\n",
       " 'TO_CHARACTERIZE': 379,\n",
       " 'TO_CITE': 380,\n",
       " 'TO_CLOSE': 381,\n",
       " 'TO_COME_OR_TO_LEAVE_SPHERE_OF_ACTIVITY': 382,\n",
       " 'TO_COMMENT': 383,\n",
       " 'TO_COMMIT': 384,\n",
       " 'TO_COMMUNICATE': 385,\n",
       " 'TO_COMPEL_AND_EVOKE': 386,\n",
       " 'TO_COMPEL_TO_ACCEPT': 387,\n",
       " 'TO_COMPOSE_SYMBOLS': 388,\n",
       " 'TO_CONCLUDE': 389,\n",
       " 'TO_CONNIVE': 390,\n",
       " 'TO_CONTRIBUTE_AND_HINDER': 391,\n",
       " 'TO_CORRECT': 392,\n",
       " 'TO_COUNT': 393,\n",
       " 'TO_COURT_AND_FLIRT': 394,\n",
       " 'TO_CREATE_HOLE': 395,\n",
       " 'TO_DECIDE': 396,\n",
       " 'TO_DESTINE': 397,\n",
       " 'TO_DEVELOP': 398,\n",
       " 'TO_DIG_PROCESS': 399,\n",
       " 'TO_DIRECT_CREATIVE_WORK': 400,\n",
       " 'TO_DISAPPEAR_LOSE_GET_RID_OF': 401,\n",
       " 'TO_DISTRACT_DEFLECT': 402,\n",
       " 'TO_DIVIDE': 403,\n",
       " 'TO_ECONOMIZE': 404,\n",
       " 'TO_EMIT': 405,\n",
       " 'TO_EXIST': 406,\n",
       " 'TO_FABRICATE': 407,\n",
       " 'TO_FEEL_AND_EXPRESS_MENTAL_ATTITUDE_TO': 408,\n",
       " 'TO_FORGIVE': 409,\n",
       " 'TO_FORM': 410,\n",
       " 'TO_FORMULATE': 411,\n",
       " 'TO_GENERATE': 412,\n",
       " 'TO_GESTURE': 413,\n",
       " 'TO_GET': 414,\n",
       " 'TO_GET_INFORMATION': 415,\n",
       " 'TO_GIVE': 416,\n",
       " 'TO_GIVE_SIGNALS': 417,\n",
       " 'TO_GO_ON_STRIKE': 418,\n",
       " 'TO_GUESS': 419,\n",
       " 'TO_HIDE': 420,\n",
       " 'TO_HURRY_TO_TARRY': 421,\n",
       " 'TO_INDEX': 422,\n",
       " 'TO_INDUCE_PHYSICAL_PROPERTIES': 423,\n",
       " 'TO_INTERACT': 424,\n",
       " 'TO_INTERCHANGE': 425,\n",
       " 'TO_INTERPRET': 426,\n",
       " 'TO_INVENT': 427,\n",
       " 'TO_INVOLVE': 428,\n",
       " 'TO_JOIN': 429,\n",
       " 'TO_JOIN_PHYSICAL_OBJECTS': 430,\n",
       " 'TO_KEEP_VIOLATE_NORMS': 431,\n",
       " 'TO_LEARN_AND_RESEARCH': 432,\n",
       " 'TO_LET_DOWN': 433,\n",
       " 'TO_LIQUIDATE': 434,\n",
       " 'TO_MAKE': 435,\n",
       " 'TO_MARRY_DIVORCE_ENGAGE': 436,\n",
       " 'TO_MEAN': 437,\n",
       " 'TO_MEASURE': 438,\n",
       " 'TO_MIX': 439,\n",
       " 'TO_MOVE_IN_GAMES': 440,\n",
       " 'TO_OPEN': 441,\n",
       " 'TO_ORGANIZE_EVENT': 442,\n",
       " 'TO_OVERTHROW': 443,\n",
       " 'TO_PARTICIPATE': 444,\n",
       " 'TO_PERCEIVE': 445,\n",
       " 'TO_PERFORM': 446,\n",
       " 'TO_PERFORM_MATHS_OPERATIONS': 447,\n",
       " 'TO_PERSUADE_SMB_TO_DO_SMTH': 448,\n",
       " 'TO_PICKET': 449,\n",
       " 'TO_PICTURE_DRAW': 450,\n",
       " 'TO_PLAN_CREATIVE_AND_PHYSICAL_OBJECTS': 451,\n",
       " 'TO_PLAY_GAMES': 452,\n",
       " 'TO_POSSESS': 453,\n",
       " 'TO_PRESS': 454,\n",
       " 'TO_PRESS_AS_TOUCH': 455,\n",
       " 'TO_PREVENT_SMTH': 456,\n",
       " 'TO_PRINT_TEXT_PHOTO': 457,\n",
       " 'TO_PROCESS_INFORMATION': 458,\n",
       " 'TO_PROCESS_PHYSICAL_OBJECT': 459,\n",
       " 'TO_PRODUCE_CERTAIN_SOUNDS': 460,\n",
       " 'TO_PROGRAM': 461,\n",
       " 'TO_PRONOUNCE': 462,\n",
       " 'TO_PROPOSE': 463,\n",
       " 'TO_PUNISH': 464,\n",
       " 'TO_RATIFY': 465,\n",
       " 'TO_REACT': 466,\n",
       " 'TO_READ_READABLE': 467,\n",
       " 'TO_REBEL': 468,\n",
       " 'TO_RECEIVE_CALLERS': 469,\n",
       " 'TO_REFLECT': 470,\n",
       " 'TO_REGISTER': 471,\n",
       " 'TO_REIGN_AS_TO_TAKE_PLACE': 472,\n",
       " 'TO_RELEASE': 473,\n",
       " 'TO_RESTORE': 474,\n",
       " 'TO_REVENGE': 475,\n",
       " 'TO_RUB_AND_SCRATCH': 476,\n",
       " 'TO_SABOTAGE': 477,\n",
       " 'TO_SCREEN': 478,\n",
       " 'TO_SEDUCE': 479,\n",
       " 'TO_SEEK_FIND': 480,\n",
       " 'TO_SEND_TO_DELIVER': 481,\n",
       " 'TO_SET': 482,\n",
       " 'TO_SHARE': 483,\n",
       " 'TO_SHINE': 484,\n",
       " 'TO_SHOOT_PHOTO_OR_FILM': 485,\n",
       " 'TO_SHOW': 486,\n",
       " 'TO_SMOKE': 487,\n",
       " 'TO_SOUND': 488,\n",
       " 'TO_SPEND': 489,\n",
       " 'TO_SPEND_INEFFECTIVELY': 490,\n",
       " 'TO_SPEND_TIME': 491,\n",
       " 'TO_SPOIL': 492,\n",
       " 'TO_STOP_SPEAKING': 493,\n",
       " 'TO_SUBSCRIBE': 494,\n",
       " 'TO_SUBSTITUTE_AND_EXCHANGE': 495,\n",
       " 'TO_SUMMARIZE': 496,\n",
       " 'TO_SUPPORT_AND_OPPOSE': 497,\n",
       " 'TO_SYMBOLIZE': 498,\n",
       " 'TO_TAKE': 499,\n",
       " 'TO_TAKE_FOOD_OR_MEDICINE': 500,\n",
       " 'TO_TAKE_INTO_CONSIDERATION': 501,\n",
       " 'TO_TAKE_PLACE': 502,\n",
       " 'TO_TAKE_PLACE_IN_NATURE': 503,\n",
       " 'TO_TEASE_AND_JOKE': 504,\n",
       " 'TO_TELEPHONE': 505,\n",
       " 'TO_TERRORIZE': 506,\n",
       " 'TO_THINK_ABOUT': 507,\n",
       " 'TO_THINK_OUT': 508,\n",
       " 'TO_TORTURE': 509,\n",
       " 'TO_TOUCH': 510,\n",
       " 'TO_TRADE': 511,\n",
       " 'TO_TURN_INTO': 512,\n",
       " 'TO_UNDERSTATE_TO_EXAGGERATE': 513,\n",
       " 'TO_USE': 514,\n",
       " 'TO_UTTER_ANIMAL_SOUNDS': 515,\n",
       " 'TO_VISUALIZE': 516,\n",
       " 'TO_WAIT': 517,\n",
       " 'TO_WORK': 518,\n",
       " 'TO_WRITE': 519,\n",
       " 'TRANSPORT': 520,\n",
       " 'TRANSPORT_COMMUNICATIONS': 521,\n",
       " 'TRIAL': 522,\n",
       " 'TRICK_MACHINATION': 523,\n",
       " 'UNCERTAINTY': 524,\n",
       " 'UNDERTAKING': 525,\n",
       " 'UNIT_OF_INFORMATION_QUANTITY': 526,\n",
       " 'UNKNOWN_SUBSTANTIVE_CLASS': 527,\n",
       " 'UNKNOWN_VERB': 528,\n",
       " 'URBAN_SPACE_AND_ROADS': 529,\n",
       " 'VALUABLE': 530,\n",
       " 'VERBAL_COMMUNICATION': 531,\n",
       " 'VIOLENCE': 532,\n",
       " 'VIRTUAL_OBJECT': 533,\n",
       " 'VIRTUAL_TRANSFERENCE': 534,\n",
       " 'VISUAL_CHARACTERISTICS': 535,\n",
       " 'VISUAL_REPRESENTATION': 536,\n",
       " 'WEAPON_AND_ITS_PART': 537,\n",
       " 'WEIGHT_CHAR': 538,\n",
       " 'WORLD_OUTLOOK': 539,\n",
       " 'YES_NO_VERBS': 540,\n",
       " '_': 541}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vocabulary import CobaldJointVocabulary\n",
    "\n",
    "vocabulary = CobaldJointVocabulary(train_dataset)\n",
    "vocabulary.semclass_tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883a135b-1563-4684-85c9-fe6b4cf553e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import NO_ARC_LABEL\n",
    "\n",
    "PADDING_VALUE = -1\n",
    "\n",
    "# Little hack to easy following pipeline\n",
    "vocabulary.deprel_ud_tagset[NO_ARC_LABEL] = PADDING_VALUE\n",
    "vocabulary.deprel_eud_tagset[NO_ARC_LABEL] = PADDING_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c9f95c-720c-4d15-a645-698219ad9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = lambda sample: vocabulary.encode(sample)\n",
    "\n",
    "train_dataset = CobaldJointDataset(\"../data/train.conllu\", transform)\n",
    "val_dataset = CobaldJointDataset(\"../data/validation.conllu\", transform)\n",
    "test_dataset = CobaldJointDataset(\"../data/test_clean.conllu\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7793a18-95b4-4d4a-815d-e2221485c8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['The',\n",
       "  'firm',\n",
       "  \"'s\",\n",
       "  'snowmobile',\n",
       "  'division',\n",
       "  'and',\n",
       "  'defence',\n",
       "  'services',\n",
       "  'unit',\n",
       "  'were',\n",
       "  'also',\n",
       "  'sold',\n",
       "  'and',\n",
       "  'Bombardier',\n",
       "  'started',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'a',\n",
       "  'new',\n",
       "  'aircraft',\n",
       "  'seating',\n",
       "  '110',\n",
       "  'to',\n",
       "  '135',\n",
       "  'passengers',\n",
       "  '.'],\n",
       " 'lemma_rules': tensor([  0,   0,   0,   0,   0,   0,   0,  13,   0, 143,   0,  74,   0,   0,\n",
       "          32,   0,   0,   0,   0,   0,   0,  63,   0,   0,   0,  13,   0]),\n",
       " 'joint_pos_feats': tensor([ 53,  79,  96,  79,  79,  50,  79,  78,  79,  34,  21, 192,  50, 152,\n",
       "         179,  53,  79,  12,  54,   2,  79, 195,  85,  12,  85,  78, 160]),\n",
       " 'deps_ud': tensor([[-1, 20, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, 34, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 38, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, 12, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, 16, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 48, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 12, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 36, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 16, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 20, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 41, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, 11, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, 20, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1,  7, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 32, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1,  1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, 42, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, 11, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, 32, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, 41, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 47, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1]]),\n",
       " 'deps_eud': tensor([[ -1,  55,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1, 102,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  42,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  46,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 122,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  43,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  46,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  46,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  49,  -1,  -1,  -1,  -1,  -1,  -1, 122,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  41,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  37,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 200,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           43,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          120,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  49,  -1,  -1,\n",
       "          200,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  55,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          126,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  42,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  55,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  38,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  93,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,   1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 127,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  42,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 110,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1, 126,  -1,  -1,  -1,  -1,  -1],\n",
       "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 198,  -1,  -1,\n",
       "           -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]]),\n",
       " 'miscs': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 1, 2]),\n",
       " 'deepslots': tensor([134, 132, 134,  72,  72, 134,  74, 119,  72, 134,   1,  95, 134,   5,\n",
       "          95, 134,  74, 134, 134, 129,  72,  85, 105, 134, 105,  72, 134]),\n",
       " 'semclasses': tensor([ 18,  96, 541, 520, 249, 113, 126, 521, 249,  20, 140, 416, 113,  96,\n",
       "          23,  18, 435, 272,  18,  78, 520, 110,  78, 272,  78,  25, 541]),\n",
       " 'metadata': {'sent_id': '2049',\n",
       "  'text': \"The firm's snowmobile division and defence services unit were also sold and Bombardier started the development of a new aircraft seating 110 to 135 passengers.\"}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351dc1d2-904e-44a6-b76a-9a04c096b3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': [['However', ',', 'the', 'DTI', 'has', 'dismissed', 'the', 'proposal', '.'], ['We', 'are', 'taken', 'as', 'hostages', '.']], 'lemma_rules': tensor([[  0,   0,   0,   0,  27,  32,   0,   0,   0],\n",
      "        [  0, 147,  13,   0,  13,   0,  -1,  -1,  -1]]), 'joint_pos_feats': tensor([[ 21, 160,  53, 150,  41, 191,  53,  79, 160],\n",
      "        [124,  32, 192, 163,  78, 160,  -1,  -1,  -1]]), 'deps_ud': tensor([[[-1, -1, -1, -1, -1, 46, -1, -1, -1],\n",
      "         [47, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, -1, 20, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, 36, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1,  9, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, 48, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, -1, -1, 20, -1],\n",
      "         [-1, -1, -1, -1, -1, 41, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, 47, -1, -1, -1]],\n",
      "\n",
      "        [[-1, -1, 38, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, 10, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, 48, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, 11, -1, -1, -1, -1],\n",
      "         [-1, -1, 42, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, 47, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "         [-1, -1, -1, -1, -1, -1, -1, -1, -1]]]), 'deps_eud': tensor([[[ -1,  -1,  -1,  -1,  -1, 197,  -1,  -1,  -1],\n",
      "         [198,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  55,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 120,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  40,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 200,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  55,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 126,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 198,  -1,  -1,  -1]],\n",
      "\n",
      "        [[ -1,  -1, 122,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  41,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1, 200,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  42,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1, 139,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1, 198,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]]]), 'miscs': tensor([[ 1,  2,  2,  2,  2,  2,  2,  1,  2],\n",
      "        [ 2,  2,  2,  2,  1,  2, -1, -1, -1]]), 'deepslots': tensor([[ 80, 134, 134,   5, 134,  95, 134,  72, 134],\n",
      "        [ 72, 134,  95, 134,  44, 134,  -1,  -1,  -1]]), 'semclasses': tensor([[140, 541,  18, 527,  20, 408,  18, 293, 541],\n",
      "        [ 25,  20, 499, 105,  25, 541,  -1,  -1,  -1]]), 'metadata': [{'sent_id': '4981', 'text': 'However, the DTI has dismissed the proposal.'}, {'sent_id': '2937', 'text': 'We are taken as hostages.'}]}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, collate_fn=CobaldJointDataset.collate_fn, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, collate_fn=CobaldJointDataset.collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=CobaldJointDataset.collate_fn, shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    if batch['deps_ud'].shape[-1] < 10:\n",
    "        print(batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f9b1d6-07fe-41ad-b9cc-b5242a9ec031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -1,  -1,  -1,  -1,  -1, 197,  -1,  -1,  -1],\n",
      "         [198,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  55,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 120,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  40,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 200,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  55,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 126,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1, 198,  -1,  -1,  -1]],\n",
      "\n",
      "        [[ -1,  -1, 122,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  41,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1, 200,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  42,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1, 139,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1, 198,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]]])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# vocabulary = vocabulary.deprel_ud_tagset[\n",
    "\n",
    "# for  in train_dataloader:\n",
    "#     if sample['deps_ud'].shape[0] < 15:\n",
    "#         break\n",
    "\n",
    "# target = sample['deps_ud']\n",
    "# target.argmax\n",
    "\n",
    "# values, indices = batch['deps_eud'][0].max(dim=-1)\n",
    "# mask = (values != -100)\n",
    "# indices\n",
    "\n",
    "target = batch['deps_eud']\n",
    "\n",
    "print(target)\n",
    "\n",
    "has_arc_mask = (target != -1)\n",
    "# # target[has_arc_mask]\n",
    "\n",
    "# s_arc = torch.rand(has_arc_mask.shape)\n",
    "mask = torch.any(has_arc_mask == True, dim=-1)\n",
    "print(mask)\n",
    "\n",
    "# arc_losses = F.binary_cross_entropy_with_logits(s_arc[mask], has_arc_mask.float(), reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a4384c3-d463-473a-a1e8-72eb4b97a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1],\n",
       "        [1, 2, 5],\n",
       "        [2, 2, 0],\n",
       "        [3, 2, 1]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rels = torch.rand([*target.shape, 7])\n",
    "pred_rels = s_rels.argmax(-1)\n",
    "(F.one_hot(pred_rels) * target_arcs[..., None]).nonzero()\n",
    "# replace_masked_values(pred_rels * target_arcs)\n",
    "# s_rels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfce6b28-2794-4254-a44f-290740db7257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f3e0b13-4f8e-4a57-8eb0-cb0f34b2e3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': tensor([[  0,   0,   3,   3],\n",
       "         [  0,   1,   4, 263],\n",
       "         [  0,   2,   3, 278],\n",
       "         [  0,   3,   3, 122],\n",
       "         [  0,   4,   3, 184],\n",
       "         [  0,   5,   4, 223],\n",
       "         [  0,   6,   4,   3],\n",
       "         [  0,   7,   3, 122],\n",
       "         [  0,   8,   3, 157],\n",
       "         [  1,   0,   0, 218],\n",
       "         [  1,   1,   1, 157],\n",
       "         [  1,   2,   5, 157],\n",
       "         [  1,   3,   3, 157],\n",
       "         [  1,   4,   3, 157],\n",
       "         [  1,   5,   1,  43]]),\n",
       " 'arc_loss': tensor(3.1764, grad_fn=<NllLossBackward0>),\n",
       " 'rel_loss': tensor(5.6563, grad_fn=<NllLossBackward0>),\n",
       " 'euas': 0.0,\n",
       " 'elas': 0.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "import dependency_classifier\n",
    "import metrics\n",
    "metrics = reload(metrics)\n",
    "dependency_classifier = reload(dependency_classifier)\n",
    "\n",
    "depcls = dependency_classifier.DependencyHead(128, 300)\n",
    "\n",
    "batch_size, seq_len, hid_dim = 2, 9, 128\n",
    "h_arc_head = torch.rand((batch_size, seq_len, hid_dim))\n",
    "h_arc_dep = torch.rand((batch_size, seq_len, hid_dim))\n",
    "h_rel_head = torch.rand((batch_size, seq_len, hid_dim))\n",
    "h_rel_dep = torch.rand((batch_size, seq_len, hid_dim))\n",
    "\n",
    "depcls(h_arc_head, h_arc_dep, h_rel_head, h_rel_dep, target != -1, target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08970e9-2e05-4753-92a0-b9d5939a99b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
